\section{Analysis II - draft}

% GDG (1. Ordnung)___________________________________________________________________________________________________
%%%%%%
\subsection{7. GDG (1. Ordnung)}

\begin{itemize}
  \item gewöhnlich: \quad \( F(x, y(x), y'(x), y''(x), \dots) = 0 \)
  \item ordnung: \quad ordnung der höchsten ableitung
  \item linear: \quad \( p_n(x)y^{(n)} + \dots + p_1(x)y' + p_0(x)y + g(x) = 0 \)
  \item homogen: \quad \( p_n(x)y^{(n)} + \dots + p_1(x)y' + p_0(x)y = 0 \)
\end{itemize}

\textbf{Superpositionsprinzip:} \quad
jede lineare kombination von lösungen einer homogenen GDG ist ebenfalls lösung der GDG.

\textbf{Satz (Lösungsraum):}

\[
\dim \mathcal{Z} = n \quad / \quad \dim \mathcal{Z}_{\mathbb{R}} = n
\]

\begin{itemize}
  \item[(i)] die menge 
    \[
    \mathcal{Z} := \left\{ f \in \mathcal{C}^n(\mathbb{R}; \mathbb{C}) \;\middle|\; f \text{ löst } \sum_{i=0}^{n} a_i(x) f^{(i)}(x) = 0 \right\}
    \]
    ist ein komplexer vektorraum.
    
  \item[(ii)] die menge 
    \[
    \mathcal{Z} := \left\{ f \in \mathcal{C}^n(\mathbb{R}; \mathbb{R}) \;\middle|\; f \text{ löst } \sum_{i=0}^{n} a_i(x) f^{(i)}(x) = 0 \right\}
    \]
    ist ein reeller vektorraum.
\end{itemize}

\textbf{GDG der Form:} \quad
$f^{(n)} + a_{n-1} f^{(n-1)} + a_{n-2} f^{(n-2)} + \dots + a_0 f = 0$

\textbf{Ansatz:} \quad $f := e^{\lambda t}$

\textbf{Satz (Basis für den Lösungsraum):} \quad
die funktionen \( f_{ik}(t) := t^k e^{\lambda_i t} \), \quad \( 1 \leq i \leq \ell, \; 0 \leq k \leq m_i \) \\
bilden eine basis des komplexen vektorraums
\[
\mathcal{Z} := \left\{ f \in \mathcal{C}^n(\mathbb{R}; \mathbb{C}) \;\middle|\; f \text{ löst } \sum_{i=0}^{n} a_i f^{(i)} = 0 \right\}
\]

\textbf{Beispiel:} \quad
\[
\ddot{f} - 2\dot{f} + f = 0 \quad \Rightarrow \quad f(t) = c_1 e^t + c_2 t e^t
\]

\vspace{1em}

\textcolor{orange}{\textbf{Zweite Ordnung}} \quad
\textbf{GDG der Form:} \quad $\ddot{f} + a\_1 \dot{f} + a\_0 f = 0$ \qquad \text{(schwingkreis)}

\[
\omega_0 := \sqrt{a_0}, \qquad \delta := \frac{a_1}{2}
\quad \Rightarrow \quad
\ddot{f} + 2\delta \dot{f} + \omega_0^2 f = 0
\]

\[
\Rightarrow \quad \mu := \sqrt{\delta^2 - \omega_0^2}, \qquad \omega_d := \sqrt{\omega_0^2 - \delta^2}
\]

\begin{itemize}
  \item[1)] \( \delta < \omega_0 \): \quad
    \( f(t) = e^{-\delta t} \left( a \cos(\omega_d t) + b \sin(\omega_d t) \right) \)

  \item[2)] \( \delta = \omega_0 \): \quad
    \( f(t) = (c_1 + c_2 t) e^{-\delta t} \)

  \item[3)] \( \delta > \omega_0 \): \quad
    \( f(t) = c_1 e^{(-\delta + \mu)t} + c_2 e^{(-\delta - \mu)t} \)
\end{itemize}


% Differentialrechnung im R___________________________________________________________________________________________________
%%%%%%
\subsection{8. Differentialrechnung im R}

\textbf{Vektorwertige Ableitung:}

Sei $g = \begin{pmatrix} g_1 \\ \vdots \\ g_p \end{pmatrix} : U \to \mathbb{R}^p$ eine Funktion mit $U \subset \mathbb{R}$ offen. 

\vspace{2pt}

Falls $g_i$ in $y_0$ differenzierbar $\forall i$, dann ist $g$ in $y_0$ differenzierbar mit
\[
g'(y_0) := \begin{pmatrix} g_1'(y_0) \\ \vdots \\ g_p'(y_0) \end{pmatrix}.
\]

\textbf{Partielle Ableitung \& Jacobi-Matrix:}

Sei $f : U \subset \mathbb{R}^n \to \mathbb{R}^p$. Dann ist die \emph{partielle Ableitung} von $f$ nach $x^j$ an der Stelle $x_0$ definiert durch:
\[
f_{x^j}(x_0) := \frac{\partial f}{\partial x^j}(x_0) := g'(x_0^j),
\]
falls $g(y) := f(x_0^1, \dots, x_0^{j-1}, y, x_0^{j+1}, \dots, x_0^n)$ in $y = x_0^j$ differenzierbar ist.

\vspace{2pt}

Falls $f$ an $x_0$ nach allen Variablen partiell differenzierbar ist, ist die \textbf{Jacobi-Matrix} gegeben durch:
\[
J_f(x_0) := \begin{pmatrix}
f_{x^1}^1(x_0) & \cdots & f_{x^n}^1(x_0) \\
\vdots & \ddots & \vdots \\
f_{x^1}^p(x_0) & \cdots & f_{x^n}^p(x_0)
\end{pmatrix}.
\]

\textbf{Totale Differenzierbarkeit \& Jacobi-Matrix:}

$f : \mathbb{R}^n \to \mathbb{R}^p$ ist in $x_0$ \emph{differenzierbar} $\Leftrightarrow$ es existiert eine lineare Abbildung $A$ mit
\[
\lim_{x \to x_0} \frac{\|f(x) - f(x_0) - A(x - x_0)\|}{\|x - x_0\|} = 0.
\]
Dann ist $A = J_f(x_0)$ die \textbf{Jacobi-Matrix} von $f$ in $x_0$:
\[
A = J_f(x_0) : \mathbb{R}^n \to \mathbb{R}^p.
\]

\textbf{Folge:} Total differenzierbar $\Rightarrow$ partiell differenzierbar.

\textbf{Totale Ableitung:}  
$Df(x_0) := df(x_0)$ ist die beste lineare Approximation von $f$ in $x_0$  
\[
Df(x_0) = J_f(x_0) = \left( \frac{\partial f^i}{\partial x^j}(x_0) \right)
\]

\textbf{Kettenregel:} Wenn $f$ in $x_0$ und $g$ in $f(x_0)$ differenzierbar sind, dann ist auch $g \circ f$ in $x_0$ differenzierbar mit
\[
d(g \circ f)(x_0) = dg(f(x_0)) \circ (df(x_0)) = dg(f(x_0)) \cdot df(x_0)
\]

\textbf{Kettenregel (Jacobi-Matrizen):} Für differenzierbare $f,g$ gilt:
\[
J_{g \circ f}(x_0) = J_g(f(x_0)) \cdot J_f(x_0)
\]
Falls $n = p = q = 1$, dann ergibt das die klassische Kettenregel:
\[
(g \circ f)'(x_0) = g'(f(x_0)) f'(x_0)
\]

\textbf{Ableitungen: Summe, Skalarprodukt, Quotient}

Seien $f, g$ differenzierbar in $x_0$:

\begin{itemize}
  \item \textbf{Summe:} $d(f + g)(x_0) = df(x_0) + dg(x_0)$
  \item \textbf{Skalarprodukt:} $d(f \cdot g)(x_0) = g(x_0) \cdot df(x_0) + f(x_0) \cdot dg(x_0)$
  \item \textbf{Quotient (für $p=1$):}
  \[
  d\left(\frac{f}{g}\right)(x_0) = \frac{g(x_0)df(x_0) - f(x_0)dg(x_0)}{(g(x_0))^2}
  \]
\end{itemize}

\textbf{Richtungsableitung:} Sei $f : \mathbb{R}^n \to \mathbb{R}^p$, $x_0 \in \mathbb{R}^n$, $v \in \mathbb{R}^n$.\\
Falls die Funktion $g : \mathbb{R} \to \mathbb{R}^p$, definiert durch
\[
g(t) := f(x_0 + tv)
\]
im Punkt $t=0$ differenzierbar ist, so definieren wir die Richtungsableitung von $f$ an der Stelle $x_0$ in Richtung $v$ durch
\[
d_v f(x_0) := D_v f(x_0) := g'(0) = 
\begin{pmatrix}
g_1'(0) \\
\vdots \\
g_p'(0)
\end{pmatrix}
\in \mathbb{R}^p.
\]

\textbf{Gradient:} Für $f : \mathbb{R}^n \to \mathbb{R}$ ist der Gradient von $f$ an der Stelle $x$ der Vektor
\[
\nabla f(x) := 
\begin{pmatrix}
D_1 f(x) \\
\vdots \\
D_n f(x)
\end{pmatrix}
=
\begin{pmatrix}
f_{x^1}(x) \\
\vdots \\
f_{x^n}(x)
\end{pmatrix}.
\]

\textbf{Stetige partielle Differenzierbarkeit:}
$f \in C^1(U, \mathbb{R}^p)$ bedeutet: $f$ ist partiell differenzierbar und alle $\partial_j f$ sind stetig.

\textbf{Folge:} $f \in C^1(U, \mathbb{R}^p) \Rightarrow f$ ist überall total differenzierbar.

\textbf{Gradientenfeld und Potential:}

Ein \emph{Vektorfeld} ist eine Abbildung \( X : U \to \mathbb{R}^n \).

Sei \( f \in C^1(U) \), dann ist das \emph{Gradientenfeld} von \( f \) gegeben durch:
\[
\nabla f(x) := 
\begin{pmatrix}
D_1 f(x) \\
\vdots \\
D_n f(x)
\end{pmatrix}
= 
\begin{pmatrix}
f_{x^1}(x) \\
\vdots \\
f_{x^n}(x)
\end{pmatrix}
.
\]

\textbf{Beispiel:} \( f(x) := \|x\|^2 \Rightarrow \nabla f(x) = 2x \)

\textbf{Potential:} Ein \emph{Potential} für ein Vektorfeld \( X \) ist eine differenzierbare Funktion \( f : U \to \mathbb{R} \) mit:
\[
\nabla f = X.
\]

\textbf{Konservativ:} Das Vektorfeld \( X \) heisst \emph{konservativ}, falls es ein Potential \( f \) besitzt.

\textbf{Wegintegral:}

\textit{Definition:} Das Wegintegral eines Vektorfeldes \( X \) längs einer Kurve \( \gamma: [a, b] \to \mathbb{R}^n \) ist definiert durch:
\[
\int_\gamma X \cdot d\gamma := \int_a^b X(\gamma(t)) \cdot \dot{\gamma}(t) \, dt.
\]

\textbf{Beispiel:} Sei \( X(x, y) := (2x, 3y) \), und \(\gamma(t) := (t, t^2) \) für \( t \in [0, 1] \). Dann:
\[
X(\gamma(t)) = (2t, 3t^2), \quad \dot{\gamma}(t) = (1, 2t),
\]
\[
X(\gamma(t)) \cdot \dot{\gamma}(t) = 2t \cdot 1 + 3t^2 \cdot 2t = 2t + 6t^3,
\]
\[
\int_\gamma X \cdot d\gamma = \int_0^1 (2t + 6t^3) \, dt = \left[t^2 + \tfrac{3}{2}t^4\right]_0^1 = 1 + \tfrac{3}{2} = \tfrac{5}{2}.
\]


\textbf{Geschlossener Weg:} \\
Ein Weg \( \gamma : [a, b] \to U \) heisst \textbf{geschlossen}, falls \( \gamma(a) = \gamma(b) \).

\vspace{0.5em}
\textbf{Satz: Charakterisierung konservativer Felder} \\
Sei \( X : U \to \mathbb{R}^n \) stetig mit \( U \subset \mathbb{R}^n \) offen. Die folgenden Aussagen sind äquivalent:

\begin{itemize}
  \item[(a)] \( X \) ist konservativ.
  \item[(b)] Das Wegintegral hängt nur von Endpunkten ab: Wenn \(\gamma_0, \gamma_1: [a,b] \to U\) stückweise stetig differenzierbar mit
  \[
    \gamma_0(a) = \gamma_1(a), \quad \gamma_0(b) = \gamma_1(b),
  \]
  dann gilt
  \[
    \int X \cdot d\gamma_0 = \int X \cdot d\gamma_1.
  \]
  \item[(c)] Für jeden geschlossenen, stetig differenzierbaren Weg \( \gamma \) gilt:
  \[
    \int_\gamma X \cdot d\gamma = 0.
  \]
\end{itemize}


\textbf{Weg-Zusammenhang und Konvexität:}

\begin{itemize}
  \item \textbf{Weg-zusammenhängend:} \( S \subset \mathbb{R}^n \) heisst weg-zusammenhängend, wenn es für alle \( x_0, x_1 \in S \) einen stetigen Weg \( \gamma: [0,1] \to S \) mit
  \[
    \gamma(0) = x_0, \quad \gamma(1) = x_1
  \]
  gibt.
  
  \item \textbf{Konvex:} \( S \subset \mathbb{R}^n \) heisst konvex, wenn für alle \( x_0, x_1 \in S \) und \( t \in [0,1] \) gilt:
  \[
    (1 - t)x_0 + tx_1 \in S.
  \]
\end{itemize}

\textbf{Konservativität überprüfen:}

\begin{enumerate}
  \item Wähle \( x_0 \in U \) und für jedes \( x \in U \) einen Weg \( \gamma_x \) von \( x_0 \) nach \( x \).
  \item Definiere \( f(x) := \int_{\gamma_x} X \cdot d\gamma \).
  \item Berechne \( \nabla f \).
  \item Falls \( \nabla f = X \), ist \( X \) konservativ, \( f \) ist Potential.
  \item Falls \( \nabla f \neq X \), ist \( X \) nicht konservativ.
\end{enumerate}

\textbf{Beispiel:}  
\( X(x, y) := (2x, 2y) \), \( U := \mathbb{R}^2 \), \( x_0 := (0,0) \),  
Wähle \( \gamma(t) = t(x,y) \Rightarrow \dot{\gamma}(t) = (x,y) \),  
\[
f(x, y) = \int_0^1 X(\gamma(t)) \cdot \dot{\gamma}(t)\,dt
= \int_0^1 2t(x^2 + y^2)\,dt = (x^2 + y^2).
\]  
Dann ist \( \nabla f = (2x, 2y) = X \Rightarrow X \) ist konservativ.

\textbf{Einfach zusammenhängend:}  
\( S \subseteq \mathbb{R}^n \) ist einfach zusammenhängend, wenn jede stetige Schleife \( \gamma : S^1 \to S \) durch eine stetige Homotopie \( h : [0,1] \times S^1 \to S \) auf einen konstanten Weg deformierbar ist:
\[
h(0, y) = \gamma(y), \quad h(1, \cdot) \text{ konstant}.
\]

\textbf{Nicht-einfach zusammenhängend:}  
\( U \subset \mathbb{R}^n \) offen ist \emph{nicht} einfach zusammenhängend, wenn es ein \( C^1 \)-Vektorfeld \( X \) gibt mit  
\[
\oint_\gamma X \cdot d\gamma \neq 0
\]
für einen geschlossenen stetig differenzierbaren Weg \( \gamma : [a,b] \to U \), obwohl \( X \) die Integrabilitätsbedingung erfüllt.

\textbf{Rotation eines Vektorfeldes}

\textit{Fall \(n=2\):} Für \( X = \begin{pmatrix} X^1 \\ X^2 \end{pmatrix} : U \subset \mathbb{R}^2 \to \mathbb{R}^2 \),
\[
\operatorname{rot} X := D_1 X^2 - D_2 X^1 = \frac{\partial X^2}{\partial x^1} - \frac{\partial X^1}{\partial x^2}
\]
\textit{Beispiel:} \( X = \begin{pmatrix} -y \\ x \end{pmatrix} \Rightarrow \operatorname{rot} X = 1 + 1 = 2 \)

\textit{Fall \(n=3\):} Für \( X = \begin{pmatrix} X^1 \\ X^2 \\ X^3 \end{pmatrix} : U \subset \mathbb{R}^3 \to \mathbb{R}^3 \),
\[
\vec{\operatorname{rot}} X := \nabla \times X = \begin{pmatrix}
D_2 X^3 - D_3 X^2 \\
D_3 X^1 - D_1 X^3 \\
D_1 X^2 - D_2 X^1
\end{pmatrix}
\]
\textit{Beispiel:} \( X = \begin{pmatrix} -y \\ x \\ 0 \end{pmatrix} \Rightarrow \vec{\operatorname{rot}} X = \begin{pmatrix} 0 \\ 0 \\ 2 \end{pmatrix} \)

\textbf{Vertauschen partieller Ableitungen:}

\textit{Nicht immer gültig!} Ein GegenBsp:
\[
f(x,y) := \begin{cases}
\frac{xy(x^2 - y^2)}{x^2 + y^2}, & (x,y)\neq(0,0) \\
0, & \text{sonst}
\end{cases}
\Rightarrow \partial_2 \partial_1 f(0,0) \ne \partial_1 \partial_2 f(0,0)
\]

\textbf{Korollar:} Falls \(f \in C^m\), dürfen partielle Ableitungen bis zur Ordnung \(m\) vertauscht werden:
\[
D_2 D_3 D_1 f = D_3 D_2 D_1 f
\]

\textit{Anwendung:} Ist \(X \in C^1\) konservativ, so gilt die Integrabilitätsbedingung:
\[
D_i X^j = D_j X^i \quad \forall\, i,j \in \{1,\dots,n\}
\]

\textbf{Taylorpolynom:} Taylorpolynom $T_{f,x_0}^m(x)$ von $f: \mathbb{R}^n \to \mathbb{R}$ um $x_0$ bis Ordnung $m$:

\[
T_{f,x_0}^m(x) := \sum_{k=0}^{m} \frac{1}{k!} \sum_{i_1,\dots,i_k=1}^{n} D_{i_k} \dots D_{i_1}f(x_0) \prod_{j=1}^{k}(x - x_0)_{i_j}
\]

\textit{Beispiel:} $f(x,y) = e^x\cos(y)$, $x_0 = (0,0)$, $m = 2$:

\[
T_{f,(0,0)}^2(x,y) = 1 + x - \frac{y^2}{2}
\]

\textbf{Taylorpolynom mit Multi-Index:}
\[
T^m_{f,x_0}(x) = \sum_{k=0}^m \sum_{\alpha \in \mathbb{N}_0^n, |\alpha| = k} \frac{1}{\alpha!} D^\alpha f(x_0) (x - x_0)^\alpha
\]

\textbf{Lemma (Multi-Index und partielle Ableitungen):}
\[
\sum_{i_1, \dots, i_k=1}^n D_{i_k} \dots D_{i_1} f(x_0) \prod_{j=1}^k v_{i_j} 
= \sum_{\alpha \in \mathbb{N}_0^n, |\alpha| = k} \binom{k}{\alpha} D^\alpha f(x_0) v^\alpha
\]

\textbf{Beispiel (Taylorpolynom bis Ordnung 2):}

Gegeben sei \( f(x_1, x_2) = e^{x_1 + x_2} \), Entwicklungspunkt \( x_0 = (0, 0) \).

Dann gilt:
\[
T^2_{f, x_0}(x) 
= f(0, 0) 
+ \nabla f(0,0) \cdot x 
+ \frac{1}{2} x^\top Hf(0,0) x
\]

Berechnung der Terme:

\[
f(0,0) = 1, \quad 
\nabla f(x) = \begin{pmatrix} \partial_{x_1} f \\ \partial_{x_2} f \end{pmatrix} 
= \begin{pmatrix} e^{x_1+x_2} \\ e^{x_1+x_2} \end{pmatrix} 
\Rightarrow \nabla f(0,0) = \begin{pmatrix} 1 \\ 1 \end{pmatrix}
\]

\scalebox{0.9}{$

\textstyle
Hf(x) = \begin{pmatrix}
\partial_{x_1}^2 f & \partial_{x_1}\partial_{x_2} f \\
\partial_{x_2}\partial_{x_1} f & \partial_{x_2}^2 f
\end{pmatrix}
= e^{x_1+x_2} \begin{pmatrix}
1 & 1 \\
1 & 1
\end{pmatrix}
\Rightarrow Hf(0,0) = \begin{pmatrix}
1 & 1 \\
1 & 1
\end{pmatrix}
$}

Einsetzen ergibt:
\[
T^2_{f, x_0}(x) 
= 1 + x_1 + x_2 + \frac{1}{2} \left( x_1^2 + 2x_1x_2 + x_2^2 \right)
\]

\textbf{Definition (Definitheit einer Matrix).} Eine symmetrische Matrix \( A \in \mathbb{R}^{n \times n} \) heisst
\begin{itemize}
  \item \textit{positiv definit}, falls \( x^\top A x > 0 \) für alle \( x \in \mathbb{R}^n \setminus \{0\} \),
  \item \textit{negativ definit}, falls \( x^\top A x < 0 \) für alle \( x \in \mathbb{R}^n \setminus \{0\} \),
  \item \textit{positiv semidefinit}, falls \( x^\top A x \geq 0 \) für alle \( x \in \mathbb{R}^n \),
  \item \textit{negativ semidefinit}, falls \( x^\top A x \leq 0 \) für alle \( x \in \mathbb{R}^n \),
  \item \textit{indefinit}, falls weder positiv noch negativ (semi)definit.
\end{itemize}


\textbf{Kritischer Punkt:} $x_0$ heisst \textit{kritisch}, falls $df(x_0) = 0$ bzw. $\nabla f(x_0) = 0$.

\textbf{Hesse-Matrix:} Für $f \in C^2(U)$ ist die Hesse-Matrix definiert als
\[
\text{Hess}_f(x_0) := \left(D_i D_j f(x_0)\right)_{i,j=1}^n
\]
{\small
\[
\mathbf{H}_f(x) :=
\begin{pmatrix}
\frac{\partial^2 f}{\partial x_1^2}(x) & \frac{\partial^2 f}{\partial x_1 \partial x_2}(x) & \cdots & \frac{\partial^2 f}{\partial x_1 \partial x_n}(x) \\
\frac{\partial^2 f}{\partial x_2 \partial x_1}(x) & \frac{\partial^2 f}{\partial x_2^2}(x) & \cdots & \frac{\partial^2 f}{\partial x_2 \partial x_n}(x) \\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial^2 f}{\partial x_n \partial x_1}(x) & \frac{\partial^2 f}{\partial x_n \partial x_2}(x) & \cdots & \frac{\partial^2 f}{\partial x_n^2}(x)
\end{pmatrix}
\]
}


Für $f \in C^2$ ist $\text{Hess}_f$ symmetrisch:
\[
\text{Hess}_f(x_0)_{ij} = \text{Hess}_f(x_0)_{ji}
\]

\textbf{Spezialfall $n = 1$:} Dann ist
\[
\text{Hess}_f(x_0) = f''(x_0)
\]

\textbf{Beispiel:} Sei $f(x_1, x_2) = x_1^2 + x_1 x_2 + x_2^2$, dann ist
\[
\text{Hess}_f(x_0) = 
\begin{pmatrix}
2 & 1 \\
1 & 2
\end{pmatrix}
\]

\textbf{Hinweis zur Anwendung:}
- Lokales Minimum bei $x_0$, falls $\nabla f(x_0) = 0$ und $\text{Hess}_f(x_0)$ positiv definit.
- Lokales Maximum bei $x_0$, falls $\nabla f(x_0) = 0$ und $\text{Hess}_f(x_0)$ negativ definit.

\textbf{Beispiel:} \( f(x, y) = x^2 + y^2 - 4x - 6y + 13 \)

\begin{itemize}
  \item \( \nabla f = (2x - 4,\, 2y - 6) \Rightarrow (x, y) = (2, 3) \)
  \item \( \text{Hess}_f =
  \begin{pmatrix}
  2 & 0 \\
  0 & 2
  \end{pmatrix} \Rightarrow \) positiv definit
  \item \( \Rightarrow \) striktes lokales Minimum bei \( (2, 3) \)
\end{itemize}

% Umkehrsatz, implizite Funktionen___________________________________________________________________________________________________
%%%%%%
\subsection{9. Umkehrsatz, implizite Funktionen, Untermannigfaltigkeit, Tangentialraum}


\textbf{Diffeomorphismus:} $f : U \to V$, $U, V \subseteq \mathbb{R}^n$ offen.\\
$f$ ist ein $C^k$-Diffeomorphismus $\Leftrightarrow$ $f$ bijektiv, $f \in C^k$, $f^{-1} \in C^k$.

\vspace{0.5em}

\textbf{Kriterium für $C^1$-Diffeomorphismus:} \\
$f$ bijektiv und $\det(df(x)) \neq 0$ für alle $x \in U$.

\vspace{0.5em}

\textbf{Umkehrsatz:} \\
$f \in C^1$, $df(x_0)$ invertierbar $\Rightarrow$ $\exists$ Umgebungen $U$ von $x_0$, $V$ von $f(x_0)$, sodass $f|_U : U \to V$ Diffeo mit Umkehrfunktion $g$ und
\[
\begin{aligned}
g(f(x)) &= x \quad &&(x \in U) \\
f(g(y)) &= y \quad &&(y \in V)
\end{aligned}
\]
und $dg(y) = (df(x))^{-1}$.

\vspace{0.5em}

$\Rightarrow$ $f$ ist \textit{lokal} Diffeo. Für \textit{global} Diffeo: zusätzlich Bijektivität auf $\Omega$ nötig.

\textbf{Implizite Funktion:} \\
Gegeben $f(x, y) = 0$, $x \in \mathbb{R}^n$, $y \in \mathbb{R}^d$. Wenn
\[
f(x_0, y_0) = 0, \quad \partial_y f(x_0, y_0) \neq 0
\]
dann existiert $y(x)$ lokal mit $f(x, y(x)) = 0$, und:
\[
dh(x) = -(\partial_y f)^{-1} \cdot \partial_x f
\]

\textit{Beispiel:} $f(x,y) = 2e^x + y(x - 1) - y^2$, $f(0,1) = 0$,\\
$\partial_y f = x - 2y$, an $(0,1) = -2 \neq 0$ $\Rightarrow$ lokal auflösbar.\\
$\partial_x y = -(\partial_y f)^{-1} \cdot \partial_x f = -(-2)^{-1} \cdot 2 = 1$

\vspace{1em}

\textbf{Untermannigfaltigkeit:} \\
$M \subseteq \mathbb{R}^n$ ist eine $k$-dimensionale $C^r$-Untermannigfaltigkeit, wenn $M$ lokal das Bild einer $C^r$-Einbettung $\psi: \Omega \to \mathbb{R}^n$ ist.\\
Oder: $M = g^{-1}(0)$ mit $g: \mathbb{R}^n \to \mathbb{R}^{n-k}$ Submersion ($dg$ hat vollen Rang).

\vspace{1em}

\textbf{Regulärer Punkt/Wert:} \\
$dg(p_0)$ voller Rang $\Rightarrow$ $p_0$ regulärer Punkt.\\
$z_0$ regulärer Wert $\Leftrightarrow$ $dg$ ist in jedem Punkt von $g^{-1}(z_0)$ surjektiv.

\vspace{0.5em}

\textbf{Satz vom regulären Wert:} \\
$z_0$ regulärer Wert $\Rightarrow$ $g^{-1}(z_0)$ ist $C^k$-Untermannigfaltigkeit der Dimension $n - d$.

\vspace{0.5em}

\textit{Beispiel:} $g(x,y) = x^2 + y^2$, $M = g^{-1}(1)$ (Einheitskreis)\\
$\nabla g = (2x, 2y) \neq 0$ $\Rightarrow$ $M$ ist $1$-dimensionale Untermannigfaltigkeit.

\vspace{1em}

\textbf{Tangentialraum:} \\
Für $M = \psi(V)$, $T_{x_0}M = \text{im}(d\psi(y_0))$.\\
Für $M = g^{-1}(0)$, $T_{x_0}M = \ker(dg(x_0))$.

\vspace{0.5em}

\textit{Beispiel:} $M = \{(x_1,x_2) \mid x_1x_2 = 1\}$,\\
$g(x_1,x_2) = x_1x_2$, $dg = (x_2, x_1)$,\\
$\Rightarrow T_{x_0}M = \{v \in \mathbb{R}^2 \mid x_2v_1 + x_1v_2 = 0\}$

z.B. bei $x = (1,1)$: $T_xM = \{(t, -t)\}$



% Mehrdimensionale Riemann-integration,Satz von Fubini über wiederholte Integration, Jordan-Mass, Substitutionsregel für mehrdimensionale Integrale___________________________________________________________________________________________________
%%%%%%
\subsection{10. Mehrdimensionale Riemann integration, Satz von Fubini über wiederholte Integration, Jordan-Mass, Substitutionsregel für mehrdimensionale Integrale}

\textbf{Treppenfunktion:}
Ein Quader \( Q = I_1 \times \dots \times I_n \) mit \( I_k = (a_k, b_k) \). \\
Volumen (Elementarinhalt): \( \mu(Q) = \prod_{k=1}^n |I_k| \). \\
Treppenfunktion:
\[
f = \sum_{k=1}^K c_k \chi_{Q_k}, \quad
\chi_{Q_k}(x) = \begin{cases}
1, & x \in Q_k \\
0, & x \notin Q_k
\end{cases}
\]
Riemann-Integral:
\[
\int_Q f\,d\mu = \sum_{k=1}^K c_k \mu(Q_k), \quad
d\mu = dx_1 \dots dx_n
\]

\vspace{0.5em}
\textbf{Eigenschaften:}
\[
f \leq g \Rightarrow \int_Q f\,d\mu \leq \int_Q g\,d\mu \qquad
\int_Q (\alpha f + \beta g)\,d\mu = \alpha \int_Q f\,d\mu + \beta \int_Q g\,d\mu
\]
\[
\left| \int_Q f\,d\mu \right| \leq \int_Q |f|\,d\mu \leq \sup_Q |f| \cdot \mu(Q)
\]

\vspace{0.5em}
\textbf{Satz von Fubini}
Für \( Q = [a,b] \times [c,d] \subset \mathbb{R}^2 \), \( f \in C^0(Q) \):
\[
\int_Q f\,d\mu = \int_a^b \left( \int_c^d f(x,y)\,dy \right)\,dx
= \int_c^d \left( \int_a^b f(x,y)\,dx \right)\,dy
\]

\vspace{0.5em}
\textbf{Jordan-Mass:}  
\( Q \subset \mathbb{R}^n \) Quader, \( \Omega \subset Q \), \( \chi_\Omega \) charakt. Funktion.  
Falls \( \mu(\Omega) = \int_Q \chi_\Omega d\mu \), dann ist \( \Omega \) Jordan-messbar.  
\( f : \Omega \to \mathbb{R} \) ist Riemann-integrierbar, falls \( \tilde{f} = 0 \) auf \( Q \setminus \Omega \) stetig fortsetzbar ist:
\[
\int_\Omega f\,d\mu = \int_Q \tilde{f}\,d\mu
\]

\vspace{0.5em}
\textbf{Substitutionsregel}
\( \Phi : \Omega \to \mathbb{R}^n \) Diffeomorphismus auf \( \Phi(\Omega) \), \( f \) integrierbar auf \( \Phi(\Omega) \):
\[
\int_{\Phi(\Omega)} f\,d\mu =
\int_\Omega (f \circ \Phi) \cdot |\det(d\Phi)|\,d\tilde{\mu}
\]
\( d\tilde{\mu} \): Integration über neue Variablen.

\vspace{0.5em}
\textbf{Beispiel:} \( f(x,y) = e^{\sqrt{x^2 + y^2}} \) über Einheitskreis \( B_1(0,0) \). \\
Substitution: \( \Phi(r,\varphi) = (r\cos\varphi,\, r\sin\varphi) \), \( \det(d\Phi) = r \)
\[
\int_{B_1} e^{\sqrt{x^2+y^2}}\,d\mu
= \int_0^1 \int_0^{2\pi} e^r \cdot r\,d\varphi\,dr
= 2\pi \int_0^1 r e^r\,dr
= 2\pi \left( re^r - e^r \right)\big|_0^1 = 2\pi(e - 1)
\]

% Vektorfelder und die Sätze von Green, Stokes und Gauss (WICHTIG!!!)___________________________________________________________________________________________________
%%%%%%
\subsection{11. Vektorfelder und die 
Sätze von Green, Stokes und Gauss}

\textbf{Kurvenintegral einer Funktion:}

Sei $C$ eine stückweise glatt parametrisierte Kurve $x_j : I_j \to \mathbb{R}^n$, dann ist das Kurvenintegral definiert durch
\[
\int_C f \, ds := \sum_j \int_{I_j} f(x_j(t)) \, \lVert \dot{x}_j(t) \rVert \, dt.
\]

\textbf{Heuristische Interpretation:}

\begin{itemize}
  \item $ds = \lVert \dot{x}_j(t_0) \rVert dt$ ist die Länge eines infinitesimalen Kurvenstücks.
  \item $\int_C f \, ds \approx \sum f(x_j(t_0)) \cdot \text{Länge}$ ist wie ein gewichteter Flächeninhalt.
  \item Geometrisch ist $\int_C f \, ds$ die Fläche unter dem Graphen von $f$ über der Kurve $C$.
\end{itemize}

\textbf{Satz (Green):}
Sei $U \subseteq \mathbb{R}^2$ ein beschränktes $C^1$-Gebiet und $X$ ein $C^1$-Vektorfeld auf $\overline{U}$. Dann gilt:
\[
\int_U \mathrm{rot}\, X \, dx = \int_{\partial U} X \cdot T \, ds.
\]

\textbf{Beispiel:}

Sei $X(x,y) = (-y, x)$ und $U$ die Einheitskreisscheibe. Dann ist
\[
\mathrm{rot}\, X = \frac{\partial x}{\partial x} - \frac{\partial (-y)}{\partial y} = 1 + 1 = 2.
\]
Flächenintegral:
\[
\int_U \mathrm{rot}\, X \, dx = \int_U 2 \, dx = 2 \cdot \text{Fläche}(U) = 2 \cdot \pi = 2\pi.
\]
Kurvenintegral über $\partial U$ (Einheitskreis, $T$ tangential):
\[
\int_{\partial U} X \cdot T \, ds = \int_0^{2\pi} 1 \cdot 1 \, d\varphi = 2\pi.
\]
Beide Seiten stimmen überein: Green'scher Satz verifiziert.

\textbf{Untermannigfaltigkeiten mit Rand}

Sei $M \subseteq \mathbb{R}^n$ eine $C^k$-Untermannigfaltigkeit der Dimension $d$ mit Rand.

\begin{itemize}
  \item \textbf{(i)} $M$ lokal diffeomorph zu $V \subseteq \mathbb{R}_+^d := \mathbb{R}^{d-1} \times [0,\infty)$.
  \item \textbf{(ii)} Eine Randparametrisierung $\psi: V \to \mathbb{R}^n$ mit $\psi$ injektiv und $C^k$-Immersion.
  \item \textbf{(iii)} Der Rand $\partial M$ ist wohldefiniert (unabhängig von Parametrisierung).
  \item \textbf{(iv)} $x_0 \in \partial M$ gdw. $\psi^{-1}(x_0) \in \mathbb{R}^{d-1} \times \{0\}$.
  \item \textbf{(v)} Für $M$ abgeschlossen, $d < n$: topologischer Rand $\ne$ intrinsischer Rand.
  \item \textbf{(vi)} Randdimension ist eindeutig bestimmt.
  \item \textbf{(vii)} $\psi$ darf $\partial M$ nicht doppelt überdecken.
  \item \textbf{(viii)} Bei Diffeomorphismen $f: (0,\infty) \to \mathbb{R}$ kann man alternative Parametrisierung $\chi(s,t) := (s, f(t))$ nutzen.
\end{itemize}

\textbf{Fluss durch eine Hyperfläche}

\textbf{Def.:} Sei $X$ ein Vektorfeld und $M$ eine orientierte $(n{-}1)$-dimensionale Fläche mit Normalenvektor $\nu$. Der \emph{Fluss} durch $M$ ist gegeben durch:
\[
\int_{M,\nu} X \cdot dA := \int_M X \cdot \nu \, dA.
\]

\textbf{Bemerkungen:}
\begin{itemize}
  \item (i) Heuristisch: $dA = \nu dA$, also:
  \[
  \int_{M,\nu} X \cdot dA = \sum_{z \in M} X \cdot dA.
  \]
  \item (ii) Für $n = 3$: Dies ist das (Oberflächen-)Flächenintegral von $X$ durch $M$.
  \item (iii) Motivation: In der Strömungsmechanik beschreibt der Fluss die Menge an „Material“, die pro Zeiteinheit durch $M$ strömt.
\end{itemize}

\textbf{Flächeninhalt:} \\
$\Phi : B \subset \mathbb{R}^2 \to \mathbb{R}^3$, $\Phi(u,v)$ parametrisiert Fläche $S = \Phi(B)$. \\
\textbf{Flächenelement:}
\[
dA = \|\partial_u \Phi \times \partial_v \Phi\| \, du\,dv = |\det(d\Phi)| \, du\,dv
\]

\textbf{Flächeninhalt:}
\[
\mu(S) = \int_S dA = \int_B \|\partial_u \Phi \times \partial_v \Phi\| \, du\,dv
\]

Allg. für $\Phi: B \subset \mathbb{R}^2 \to \mathbb{R}^n$:
\[
dA = \sqrt{\det((d\Phi)^T \cdot d\Phi)} \, d\mu
\]

\vspace{1em}

\textbf{Oberflächenintegral:} \\
$f : S \subset \mathbb{R}^3 \to \mathbb{R}$, $S = \Phi(B)$ parametrisiert:
\[
\int_S f(x,y,z)\, dA = \int_B f(\Phi(u,v)) \cdot \|\partial_u \Phi \times \partial_v \Phi\| \, du\,dv
\]

\vspace{1em}

\textbf{Koorientierung (Normalenvektor):}
\[
\vec{n} = \frac{\partial_u \Phi \times \partial_v \Phi}{\|\partial_u \Phi \times \partial_v \Phi\|}
\]



\textbf{Satz (Stokes):} \\
\[
\text{Für ein } C^1\text{-Vektorfeld } X : U \to \mathbb{R}^3, \text{ orientierte Fläche } \Sigma \subset \mathbb{R}^3: 
\]
\[
\int_{\Sigma, \nu} (\nabla \times X) \cdot dA 
= \int_{\Sigma} (\nabla \times X) \cdot \nu \, dA 
= \int_{\partial \Sigma, T} X \cdot ds 
= \int_{\partial \Sigma} X \cdot T \, ds
\]
\[
\textbf{Beispiel:} \text{ Sei } \Sigma := \{x \in S^2 \mid x_3 \geq a \}, \quad \nu(x) := x, \, a > 0. \\
\text{Gegeben:}
\]
\[
X(x) := \frac{1}{2}(-x_2, x_1, 0), \quad T(x) := \frac{1}{\sqrt{1 - a^2}}(-x_2, x_1, 0)
\]

\text{Dann:}
\[
\nabla \times X = (0, 0, 1) = e_3
\]

$\text{Fluss durch } \Sigma: $
\[
\int_{\Sigma, \nu} e_3 \cdot dA 
= \int_{\partial \Sigma} X \cdot T \, ds 
= \int_{S^1} \frac{1}{\sqrt{1-a^2}} ((-x_2)^2 + x_1^2) \, ds 
= \frac{1}{\sqrt{1 - a^2}} \int_{S^1} (x_1^2 + x_2^2) \, ds
\]

$\text{Auf Kreisradius } \sqrt{1 - a^2}: $
\[
= \frac{1}{\sqrt{1 - a^2}} (1 - a^2) \cdot 2\pi\sqrt{1 - a^2}
= 2\pi (1 - a^2)
\]

\textbf{Definition: Koorientierung eines Randes}

Sei $U \subset \mathbb{R}^n$ ein $C^1$-Gebiet und $g \in C^1(U, \mathbb{R})$ mit $\partial U = \{x \in U : g(x) = 0\}$, $\nabla g(x_0) \neq 0$.  
Dann ist die nach außen zeigende \textit{koorientierte} Einheitsnormalenabbildung
\[
\nu: \partial U \to \mathbb{R}^n, \quad \nu(x) := \frac{\nabla g(x)}{\|\nabla g(x)\|}.
\]

\textbf{Eigenschaft:}  
Die Koorientierung definiert eine Orientierung für $\partial U$ konsistent mit $U$.

\textbf{Satz von Gauß (Divergenzsatz)}

Sei $U \subseteq \mathbb{R}^n$ ein beschränktes $C^1$-Gebiet und $X \in C^1(\overline{U}, \mathbb{R}^n)$. Dann gilt:

\[
\int_U \operatorname{div} X \, dx = \int_{\partial U, \nu} X \cdot dA = \int_{\partial U} X \cdot \nu \, dA
\]

Dabei ist $\nu$ das nach aussen weisende Einheitsnormalenfeld auf $\partial U$.

\textbf{Beispiel ($n=1$)}
Für $f = X^1$ und $U = (a,b)$:

\[
\int_a^b f'(x)\, dx = f(b) - f(a)
\]

\textbf{Begründung:} Mit $X = f$ ist $\operatorname{div} X = f'$ und
\[
\int_U \operatorname{div} X \, dx = \int_{\partial U} f \cdot \nu = f(b)\cdot 1 + f(a)\cdot (-1) = f(b) - f(a)
\]

\textbf{Folgerung aus Gauß:}

Aus dem Gaußschen Integralsatz folgt:
\scalebox{0.8}{$
\int_U \operatorname{rot} X\,dx = \int_U \nabla \cdot Y\,dx = 
\int_{\partial U} Y \cdot \nu\,dA = 
\int_{\partial U} (X^2 T^2 - X^1 (-T^1))\,ds = 
\int_{\partial U} X \cdot T\,ds
$}


% Weiteres___________________________________________________________________________________________________
%%%%%%
\subsection{12. Zusatz (Integraltabellen, Bilder etc.)}

\textbf{Ansätze für inhomogene DGLs:}

\begin{center}
\renewcommand{\arraystretch}{1.4}
\begin{tabular}{|
  >{\centering\arraybackslash}m{4cm}|
  >{\centering\arraybackslash}m{4cm}|
}
\hline
$g(t)$ & $y_{\text{part}}(t)$ \\
\hline
$C$ & $A$ \\
$Ce^{at}$ & $Ae^{at}$ \\
$C\cos(bt)$ & $A\sin(bt) + B\cos(bt)$ \\
$C\sin(bt)$ & $A\sin(bt) + B\cos(bt)$ \\
$C\cos(bt)e^{at}$ & $(A\sin(bt) + B\cos(bt))e^{at}$ \\
$C\sin(bt)e^{at}$ & $(A\sin(bt) + B\cos(bt))e^{at}$ \\
$k_nt^n + \cdots + k_0$ & $K_nt^n + \cdots + K_0$ \\
$(k_nt^n + \cdots + k_0)e^{at}$ & $(K_nt^n + \cdots + K_0)e^{at}$ \\
$(k_nt^n + \cdots + k_0)\cos(bt)$ &
$\begin{aligned}
&(K_nt^n + \cdots)\sin(bt)\\
&+ (M_nt^n + \cdots)\cos(bt)
\end{aligned}$ \\
$(k_nt^n + \cdots + k_0)\sin(bt)$ &
$\begin{aligned}
&(K_nt^n + \cdots)\sin(bt)\\
&+ (M_nt^n + \cdots)\cos(bt)
\end{aligned}$ \\
\hline
\end{tabular}
\end{center}


\textbf{Parametrisierungen}

\vspace{0.5em}

\textbf{Kreis:} $\Phi : (0, \infty) \times [0, 2\pi) \to \mathbb{R}^2$
\[
\Phi(r, \varphi) = \begin{pmatrix} r\cos\varphi \\ r\sin\varphi \end{pmatrix}, \quad
\det(d\Phi) = r, \quad
d\mu = r\,dr\,d\varphi
\]

\textbf{Ellipse:} $\Phi : (0, \infty) \times [0, 2\pi) \to \mathbb{R}^2$
\[
\Phi(r, \varphi) = \begin{pmatrix} ra\cos\varphi \\ rb\sin\varphi \end{pmatrix}, \quad
\det(d\Phi) = abr, \quad
d\mu = abr\,dr\,d\varphi
\]

\textbf{Zylinder:} $\Phi : (0, \infty) \times [0, 2\pi) \times \mathbb{R} \to \mathbb{R}^3$
\[
\Phi(r, \varphi, h) = \begin{pmatrix} r\cos\varphi \\ r\sin\varphi \\ h \end{pmatrix}, \quad
\det(d\Phi) = r, \quad
d\mu = r\,dr\,d\varphi\,dh
\]

\textbf{Kugel:} $\Phi : (0, \infty) \times [0, 2\pi) \times [0, \pi] \to \mathbb{R}^3$
\[
\Phi(r, \theta, \varphi) =
\begin{pmatrix}
r\cos\varphi\sin\theta \\
r\sin\varphi\sin\theta \\
r\cos\theta
\end{pmatrix}, \quad
\det(d\Phi) = r^2\sin\theta, \quad
d\mu = r^2\sin\theta\,dr\,d\varphi\,d\theta
\]

\textbf{Ellipsoid:} $\Phi : (0, \infty) \times [0, 2\pi) \times [0, \pi] \to \mathbb{R}^3$
\[
\Phi(r, \theta, \varphi) =
\begin{pmatrix}
ar\cos\varphi\sin\theta \\
br\sin\varphi\sin\theta \\
cr\cos\theta
\end{pmatrix}, \quad
\det(d\Phi) = abcr^2\sin\theta, \quad
d\mu = abcr^2\sin\theta\,dr\,d\varphi\,d\theta
\]

\vspace{1em}
\noindent
{\textbullet\ Für den Rand des Körpers muss jeweils die Parametrisierung mit einem konstanten \( r \) genommen werden.}



\begin{center}
\renewcommand{\arraystretch}{1.3}
\setlength{\tabcolsep}{8pt}
\begin{tabular}{@{}ll@{}}
\multicolumn{2}{c}{\textbf{Punktmengen}} \\
\textbf{Gerade} &
$M = \left\{(x,y) \in \mathbb{R}^2 \mid y = mx + q \right\}$ \\
\textbf{Kreis} &
$M = \left\{(x,y) \in \mathbb{R}^2 \mid (x - x_0)^2 + (y - y_0)^2 = r^2 \right\}$ \\
\textbf{Ellipse} &
$M = \left\{(x,y) \in \mathbb{R}^2 \mid \frac{(x - x_0)^2}{a^2} + \frac{(y - y_0)^2}{b^2} = 1 \right\}$ \\
\textbf{Hyperbel} &
$M = \left\{(x,y) \in \mathbb{R}^2 \mid \frac{x^2}{a^2} - \frac{y^2}{b^2} = 1 \right\}$ \\
\textbf{Kugel} &
$M = \left\{(x,y,z) \in \mathbb{R}^3 \mid (x - x_0)^2 + (y - y_0)^2 + (z - z_0)^2 = r^2 \right\}$ \\
\textbf{Ellipsoid} &
$M = \left\{(x,y,z) \in \mathbb{R}^3 \mid \frac{(x - x_0)^2}{a^2} + \frac{(y - y_0)^2}{b^2} + \frac{(z - z_0)^2}{c^2} = 1 \right\}$ \\
\textbf{Kegel} &
$M = \left\{(x,y,z) \in \mathbb{R}^3 \mid x^2 + y^2 = \frac{r^2}{h}(h - z) \right\}$ \\
\textbf{Zylinder} &
$M = \left\{(x,y,z) \in \mathbb{R}^3 \mid (x - x_0)^2 + (y - y_0)^2 = r^2 \right\}$ \\
\end{tabular}
\end{center}


\begin{center}
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{|>{$}c<{$}|>{$}c<{$}|>{$}c<{$}|}
\hline
f'(x) & f(x) & \int f(x)\,dx \\
\hline
0 & c & cx \\
nx^{n-1} & x^n & \frac{x^{n+1}}{n+1} \\
-\frac{1}{x^2} & \frac{1}{x} & \ln|x| \\
\frac{n}{x^{n+1}} & \frac{1}{x^n} & \frac{-1}{(n-1)x^{n-1}} \\
\frac{1}{2\sqrt{x}} & \sqrt{x} & \frac{2}{3}x^{3/2} \\
ae^{ax} & e^{ax} & \frac{1}{a}e^{ax} \\
\frac{1}{x} & \ln|x| & x(\ln x - 1) \\
\cos(x) & \sin(x) & -\cos(x) \\
-\sin(x) & \cos(x) & \sin(x) \\
\frac{1}{\cos^2(x)} & \tan(x) & -\ln|\cos(x)| \\
\cosh(x) & \sinh(x) & \cosh(x) \\
\sinh(x) & \cosh(x) & \sinh(x) \\
\frac{1}{\cosh^2(x)} & \tanh(x) & \ln(\cosh(x)) \\
\frac{1}{1+x^2} & \arctan(x) & x\arctan(x) - \frac{\ln(x^2+1)}{2}\\
\frac{1}{\sqrt{1 - x^2}} & \arcsin(x) & x \arcsin(x) + \sqrt{1-x^2}\\
-\frac{1}{\sqrt{1 - x^2}} & \arccos(x) & x \arccos(x) - \sqrt{1-x^2}\\
\frac{1}{\sqrt{1 + x^2}} & \text{arcsinh}(x) & x \text{arcsinh}(x) - \sqrt{x^2+1} \\
\frac{1}{\sqrt{x^2 - 1}} & \text{arccosh}(x) & x \text{arccosh}(x) - \sqrt{x^2-1} \\
\frac{1}{m((x+k)^2 + m^2)} & \frac{1}{(x+k)^2 + m^2} & \frac{1}{m} \arctan\left(\frac{x + k}{m}\right) \\
\hline
\end{tabular}
\end{center}

\doublebox{
\begin{minipage}{\linewidth}
\textbf{Unentscheidbare Fälle} \\
Es gilt
\[
\frac{1}{0} = \infty \qquad
\frac{1}{\infty} = 0 \qquad
\infty + \infty = \infty \qquad
0 + \infty = \infty \qquad
0^\infty = 0 \qquad
\infty^0 = \infty
\]

Folgende Fälle sind jedoch unentscheidbar:
\[
\frac{0}{0} \quad \infty - \infty \quad
1^\infty \quad 0^0 \quad 0 \cdot \infty
\]
\end{minipage}
}

\vspace{1em}

\doublebox{
\begin{minipage}{\linewidth}
\textbf{Dominanz} \\
Es gilt für $x \to +\infty$
\[
\log(\log(x)) < \log(x) < x^q < x^p < a^x < b^x < x! < x^x
\]
wobei $0 < q < p < a < b$. \\
Für $x \to 0^+$ gilt die Reihenfolge genau umgekehrt.
\end{minipage}
}